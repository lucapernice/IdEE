---
layout: post
title: "Integration of Genetic Algorithms and Language Models: Part 2"
author: luca
categories: [ LLM, Artificial Intelligence ]
image: assets/images/dna.jpeg
description: "This second part of the article explore another paper for Code-Level Neural Architecture Search "
---

This is the second part of the article, focusing on optimizing code with LLMs and Genetic Algorithms. 

### ([**LINK TO PART 1**](https://lucapernice.github.io/IdEE//GA_prompt/))

# EvoPrompting

Reference paper [4]: [**EvoPrompting: Language Models for Code-Level Neural Architecture Search**](https://arxiv.org/abs/2302.14838)

> *Note:* I haven’t included any code in this section as running it on my laptop would be both **costly** and **time-consuming**. This serves as a brief overview of a more sophisticated implementation involving **Genetic Algorithms (GA)** and **Language Models (LLMs)**. It also presents an alternative to the **Neural Architecture Search (NAS)** method covered in our course lectures.

In the preceding part of the article, the **evolved prompts** consisted of natural language sentences. Given the proficiency of **language models** in working with programming code, the current aim is to utilize these models to generate new code. **Genetic Programming** typically requires a representation of the program, often in the form of a tree or a stream of instructions. By capitalizing on the language model’s capacity to handle **code strings**, the program can essentially be represented by its own code. This eliminates the necessity of manually designing a search space, encompassing any syntactically valid piece of code within the search domain.

The referenced paper introduces a method named **EvoPrompting** for **Code-Level Neural Architecture Search**. Although **EvoPrompt** and **EvoPrompting** share a similar approach (and similar names), a closer examination reveals several differences. 

The primary concept behind the **EvoPrompting** (Figure 4) method involves initializing a population of codes, specifically **neural network architectures**. However, unlike random code generation, these codes are well-known and carefully designed. Let’s consider the example of the **Crossover** and **Mutation** prompts outlined in the paper (Figure 3).

<div style="text-align:center">
  <figure>
    <img src="{{ site.baseurl }}/assets/images/Schermata del 2023-12-16 18-43-20.png" alt="Figure 3" width="70%">
    <figcaption>Figure 3: An example of a few-shot prompt (pag. 5 of the paper). The second in-context example here is omitted for brevity </figcaption>
  </figure>
</div>

An usual requirement for effective **crossover** or **mutation** operators is 'unbiasedness'. These operators must be random and independent of the fitness value. This **randomness** is crucial to explore the search space adequately and prevent rapid convergence to a local optimum. The paper introduces a crucial aspect: 

> "In the last line of the prompt, we create a target set of metrics to condition πθ’s generations, indicating the desired validation accuracy and model size of the proposed architecture."

This suggests that starting with a population of already high-quality code reduces the need for extensive exploration in the search space, minimizing bias-related issues.

A notable distinction between this few-shot prompt example and the prompts offered by the **EvoPrompt** framework, as seen in the previous section, is the absence of instructions here. The prompt is constructed solely using a fixed number of shots, with each shot comprising a line detailing a target set of metrics and then the program code lines associated with a parent from the population. It would be interesting to observe how a prompt designed with specific instructions would appear and function in this context.

It’s important to clarify: in the previous section of this report, while experimenting with different **crossover** prompts, there was a discussion about avoiding bias by not using few-shot prompting. However, in that context, the 'shots' were intended as examples of performing crossover, resulting in hand-designed offsprings. In this scenario, when the paper mentions 'shots', it refers to a single parent code and not as an example of hand-made crossover.

<div style="text-align:center">
  <figure>
    <img src="{{ site.baseurl }}/assets/images/2-Figure1-1.png" alt="Figure 4" width="70%">
    <figcaption>Figure 4: An overview of EVOPROMPTING (taken from page 2 of the paper).</figcaption>
  </figure>
</div>

## Conclusion

Both the **EvoPrompt** and **EvoPrompting** papers feature tables and graphs displaying their results, which are not duplicated in this report. Interested readers can refer to the papers via the provided links for details.

Instead, concluding this report necessitates a final observation regarding the **Colab code**, an addition that doesn’t exist in the referenced papers. First, it’s worth highlighting the ease of implementing the **GA algorithm**. There’s no need to manually design and code crossover and mutation functions as the language model autonomously manages these operations. Admittedly, a well-designed prompt is essential for the language model’s effectiveness. Nonetheless, the synergy between **GA** and **LLMs** is fascinating, leveraging the language model’s natural language capabilities to optimize its own inputs.

Another noteworthy point is that while **Stable Beluga 2** is utilized here instead of **GPT** as featured in the papers, at least for GA, it demonstrates commendable performance. It would be intriguing to explore how different language models execute evolutionary operators, including assessing their scalability.

Moreover, the speed at which the implemented GA converges is remarkable. As depicted in Figure 1 of the previous article, the fitness swiftly converges within a few iterations to reach a local optimum. In this instance, constrained computational time necessitated a swift convergence, although being stuck in a local optimum isn’t typically favorable. The challenge arises as the language model conducts mutations, providing limited control. The only controllable parameters are the selection pressure, independent of the language model, and the model’s temperature. Although crafting specific prompts for mutation like "perform a smaller/larger mutation" might seem a plausible approach, it didn’t work for me with Stable Beluga 2.

Regarding the **temperature** of the model, it’s crucial to note that higher values may sacrifice precision, potentially causing the output to deviate from the input prompt’s instructions.
